{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2018/7/25 09:28\n",
    "# @Author  : Xiaoyu Xing\n",
    "# @File    : make_dic.py\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename, \"r\") as fw:\n",
    "        sentences = []\n",
    "        sentence = []\n",
    "        for line in fw:\n",
    "            if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == '\\n':\n",
    "                if len(sentence) > 0:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "                continue\n",
    "            else:\n",
    "                splits = line.split(' ')\n",
    "                sentence.append([splits[0].strip(), splits[1].strip()])\n",
    "\n",
    "        if len(sentence) > 0:\n",
    "            sentences.append(sentence)\n",
    "            sentence = []\n",
    "\n",
    "        return sentences\n",
    "\n",
    "\n",
    "personDic = defaultdict(int)\n",
    "locDic = defaultdict(int)\n",
    "orgDic = defaultdict(int)\n",
    "miscDic = defaultdict(int)\n",
    "\n",
    "sentences1 = readfile(\"data/webpages/webpages.train.txt\")\n",
    "# sentences2 = readfile(\"data/webpages/webpages.valid.txt\")\n",
    "sentences3 = readfile(\"data/webpages/webpages.test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDic(sentences,personDic,locDic,orgDic,miscDic):\n",
    "    for sentence in sentences:\n",
    "        for i, (word, label) in enumerate(sentence):\n",
    "            phase = word\n",
    "            if label!='O':\n",
    "                splits = label.split(\"-\")\n",
    "                tag = splits[0]\n",
    "                entityLabel = splits[1]\n",
    "                if tag == 'B':\n",
    "                    j = i + 1\n",
    "                    while (j < len(sentence)):\n",
    "                        if sentence[j][1] != 'O':\n",
    "                            tag2 = sentence[j][1].split('-')[0]\n",
    "                            entityLabel2 = sentence[j][1].split('-')[1]\n",
    "                            if (tag2 == 'I' and entityLabel2 == entityLabel):\n",
    "                                phase = phase + \" \" + sentence[j][0]\n",
    "                                j += 1\n",
    "                                if j==len(sentence):\n",
    "                                    if entityLabel == \"PER\":\n",
    "                                        personDic[phase] += 1\n",
    "                                    elif entityLabel == \"LOC\":\n",
    "                                        locDic[phase] += 1\n",
    "                                    elif entityLabel == \"ORG\":\n",
    "                                        orgDic[phase] += 1\n",
    "                                    elif entityLabel ==\"MISC\":\n",
    "                                        miscDic[phase]+=1\n",
    "                                    break\n",
    "                            else:\n",
    "                                if entityLabel == \"PER\":\n",
    "                                    personDic[phase] += 1\n",
    "                                elif entityLabel == \"LOC\":\n",
    "                                    locDic[phase] += 1\n",
    "                                elif entityLabel == \"ORG\":\n",
    "                                    orgDic[phase] += 1\n",
    "                                elif entityLabel ==\"MISC\":\n",
    "                                    miscDic[phase]+=1\n",
    "                                break\n",
    "                        else:\n",
    "                            if entityLabel == \"PER\":\n",
    "                                personDic[phase] += 1\n",
    "                            elif entityLabel == \"LOC\":\n",
    "                                locDic[phase] += 1\n",
    "                            elif entityLabel == \"ORG\":\n",
    "                                orgDic[phase] += 1\n",
    "                            elif entityLabel ==\"MISC\":\n",
    "                                miscDic[phase]+=1\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "addDic(sentences1,personDic,locDic,orgDic,miscDic)\n",
    "# addDic(sentences2,personDic,locDic,orgDic,miscDic)\n",
    "addDic(sentences3,personDic,locDic,orgDic,miscDic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dictionary/person.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        personDic[line]+=1\n",
    "with open(\"dictionary/location.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        locDic[line]+=1\n",
    "with open(\"dictionary/organization.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        orgDic[line]+=1\n",
    "with open(\"dictionary/misc.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        miscDic[line]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_big_dic(dic,fileName):\n",
    "    with open(fileName,\"w\") as fw:\n",
    "        for key,value in dic.items():\n",
    "            fw.write(key+\"\\n\")\n",
    "make_big_dic(personDic,\"personBigDic.txt\")\n",
    "make_big_dic(locDic,\"locationBigDic.txt\")\n",
    "make_big_dic(orgDic,\"organizationBigDic.txt\")\n",
    "make_big_dic(miscDic,\"miscBigDic.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2731481481481481\n",
      "33\n",
      "216\n",
      "['Fedkiw, R.', 'Cuba', 'Tamar Shinar', 'Donald E. Troxel', 'Jeong-Mo Hong', 'Ken Thompson', 'Eftychios Sifakis', 'Geoffrey Irving', 'Shinar, T.', 'Frank Losasso', 'Peter', 'Losasso, F.', 'Rob Pike', 'Burgers', 'Andrew Selle', 'Binkley, Timothy.', 'Moritz, William.', 'Gary', 'Hong, J.-M.', 'Joey Teran', 'Nipun Kwatra', 'J. Popovic', 'Craig Schroeder', 'Sifakis, E.', 'Anant Agarwal', 'Rajeev Motwani', 'D. Metaxas', 'Ian Mitchell', 'Josh Bao', 'Larry Cuba', 'John Whitney, Sr.', 'Kevin Der', 'Lillian Schwartz']\n"
     ]
    }
   ],
   "source": [
    "pdf = DataFrame()\n",
    "pdf[\"name\"] = list(personDic.keys())\n",
    "pdf[\"value\"] = list(personDic.values())\n",
    "pdf = pdf.sort_values(by=['value'],ascending=False)\n",
    "print(pdf[\"value\"].mean())\n",
    "highPName = pdf[pdf.value>=2][\"name\"].tolist()\n",
    "print(len(highPName))\n",
    "print(len(pdf))\n",
    "print(highPName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2222222222222223\n",
      "4\n",
      "72\n",
      "                                       name  value\n",
      "5                                      Cuba      8\n",
      "29                                   Madras      5\n",
      "0                                        UK      4\n",
      "17                                      USA      3\n",
      "41                                 Scotland      1\n",
      "42                           Gates building      1\n",
      "40                                    Knopf      1\n",
      "43                                 Matanzas      1\n",
      "44                                 Kodansha      1\n",
      "45   Gates Computer Science Bldg., Room 207      1\n",
      "54                 The Amsterdam Filmmuseum      1\n",
      "46                              Los Angeles      1\n",
      "47                                Hiroshima      1\n",
      "48                                   Zagreb      1\n",
      "49                                  Bangkok      1\n",
      "50          New York's Museum of Modern Art      1\n",
      "51                     The Hirshhorn Museum      1\n",
      "52   The San Francisco Museum of Modern Art      1\n",
      "53             The Art Institute of Chicago      1\n",
      "56                                    Paris      1\n",
      "55             Isetan Museum of Art, Tokyo.      1\n",
      "64                                   Turkey      1\n",
      "70                                 Oklahoma      1\n",
      "69                                    Tulsa      1\n",
      "68                                    Japan      1\n",
      "67                                  Amherst      1\n",
      "66                            Syracuse , NY      1\n",
      "65                                MC 136-93      1\n",
      "63                                Frankfurt      1\n",
      "38                               Tamil Nadu      1\n",
      "62                                    China      1\n",
      "61                            United States      1\n",
      "60  5000 Forbes Avenue Pittsburgh, PA 15213      1\n",
      "59                         Bangalore, India      1\n",
      "58                  Stanford, CA 94305-9020      1\n",
      "57                                     U.S.      1\n",
      "39                   Baton Rouge, La., USA.      1\n",
      "36       Gates Computer Science Building 4B      1\n",
      "37                                St. Louis      1\n",
      "10                                 Florence      1\n"
     ]
    }
   ],
   "source": [
    "ldf = DataFrame()\n",
    "ldf[\"name\"] = list(locDic.keys())\n",
    "ldf[\"value\"] = list(locDic.values())\n",
    "ldf = ldf.sort_values(by=['value'],ascending=False)\n",
    "print(ldf[\"value\"].mean())\n",
    "highLName = ldf[ldf.value>=2][\"name\"].tolist()\n",
    "print(len(highLName))\n",
    "print(len(ldf))\n",
    "print(ldf[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1764705882352942\n",
      "21\n",
      "187\n",
      "                                              name  value\n",
      "1                              Stanford University      7\n",
      "0                         Industrial Light + Magic      3\n",
      "51                                             MIT      3\n",
      "33                                            UCLA      3\n",
      "18               University of Colorado at Boulder      3\n",
      "87                                         Caltech      3\n",
      "28                  University of British Columbia      3\n",
      "2                                      ACL-08: HLT      3\n",
      "124                                      Bell Labs      2\n",
      "114                                 Addison-Wesley      2\n",
      "81     University of North Carolina at Chapel Hill      2\n",
      "116                         University of Maryland      2\n",
      "20           Massachusetts Institute of Technology      2\n",
      "19     Academy of Motion Picture Arts and Sciences      2\n",
      "48                                 Ars Electronica      2\n",
      "154                                  Prentice Hall      2\n",
      "111                                        Rutgers      2\n",
      "32                                        Stanford      2\n",
      "38                              Microsoft Research      2\n",
      "96                                       bell labs      2\n",
      "78                                          google      2\n",
      "131                          MIT Technology Review      1\n",
      "128  Database Group/InfoLab, and Foundations Group      1\n",
      "127                   National Academy of Sciences      1\n",
      "129                                        iSchool      1\n",
      "130                                     FTP online      1\n",
      "106                                        Inferno      1\n",
      "132                           Max Planck Institute      1\n",
      "133                                Lockheed Martin      1\n",
      "126                                            SRI      1\n",
      "135       The David and Lucille Packard Foundation      1\n",
      "136                                           NICT      1\n",
      "137                        Pixar Animation Studios      1\n",
      "138                                      Judo Club      1\n",
      "139                                       Siggraph      1\n",
      "134                Master of Engineering Committee      1\n",
      "122                   University of North Carolina      1\n",
      "125                                  Coolfreepages      1\n",
      "115                                 Simon Fraser U      1\n",
      "108                                  IEEE Computer      1\n"
     ]
    }
   ],
   "source": [
    "odf = DataFrame()\n",
    "odf[\"name\"] = list(orgDic.keys())\n",
    "odf[\"value\"] = list(orgDic.values())\n",
    "odf = odf.sort_values(by=['value'],ascending=False)\n",
    "print(odf[\"value\"].mean())\n",
    "highOName = odf[odf.value>=2][\"name\"].tolist()\n",
    "print(len(highOName))\n",
    "print(len(odf))\n",
    "print(odf[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1219512195121952\n",
      "12\n",
      "164\n",
      "                                                  name  value\n",
      "41                                                Spin      6\n",
      "68                                           Pico/Popi      3\n",
      "22                              Electrical Engineering      3\n",
      "128                                               Lord      3\n",
      "135                                          Sociology      3\n",
      "25                                        VirtualWires      2\n",
      "83                                     J. Sci. Comput.      2\n",
      "1                                               PECASE      2\n",
      "44                                         Mathematics      2\n",
      "143                             electrical engineering      2\n",
      "94   ACM SIGGRAPH/Eurographics Symposium on Compute...      2\n",
      "107                                   Computer Science      2\n",
      "108                     Computation and Neural Systems      1\n",
      "109                                         microtrace      1\n",
      "110  IEEE Transactions on Knowledge and Data Engine...      1\n",
      "111                                 Software Assurance      1\n",
      "0                                        Mark 12:29-31      1\n",
      "112  \"10 Emerging Technologies That Will Change the...      1\n",
      "113            Journal of Computer and System Sciences      1\n",
      "114  Institute for Computational and Mathematical E...      1\n",
      "116                                      SIGGRAPH 2007      1\n",
      "117                                            ACM TOG      1\n",
      "118           AT&T Bell Laboratories Technical Journal      1\n",
      "119  Mathematical Methods for Robotics, Vision and ...      1\n",
      "120           Models and Issues in Data Stream Systems      1\n",
      "115            \"Wrinkled Flames and Cellular Patterns\"      1\n",
      "104                                             Feaver      1\n",
      "106                                              Modex      1\n",
      "96                         ACM SIGGRAPH Awards Program      1\n",
      "88                        \"An Analytical Cache Model.\"      1\n",
      "89                ACM Transactions on Computer Systems      1\n",
      "90   Two way coupled SPH and particle level set flu...      1\n",
      "91   \"Spatially Adaptive Techniques for Level Set M...      1\n",
      "92                                Computers and Fluids      1\n",
      "93            \"Hybrid Simulation of Deformable Solids\"      1\n",
      "95                                              Pico's      1\n",
      "97                                 ACM SIGGRAPH Awards      1\n",
      "105                                  Lucent's PathStar      1\n",
      "98                     CNN Science & Technology report      1\n",
      "99                             Thin shell rigid bodies      1\n",
      "100                                     Chess Endgames      1\n",
      "101            Arbitrary cutting of tetrahedral meshes      1\n",
      "102                                          pixelface      1\n",
      "103                                     Smart Machines      1\n",
      "122                        Fire with cellular patterns      1\n",
      "121  \"On Boundary Condition Capturing for Multiphas...      1\n",
      "125            Fellowships for Science and Engineering      1\n",
      "123  The Spin Model Checker - Primer and Reference ...      1\n",
      "154         Beyond Photography -- The Digital Darkroom      1\n",
      "147                                Associate Professor      1\n"
     ]
    }
   ],
   "source": [
    "mdf = DataFrame()\n",
    "mdf[\"name\"] = list(miscDic.keys())\n",
    "mdf[\"value\"] = list(miscDic.values())\n",
    "mdf = mdf.sort_values(by=['value'],ascending=False)\n",
    "print(mdf[\"value\"].mean())\n",
    "highMName = mdf[mdf.value>=2][\"name\"].tolist()\n",
    "print(len(highMName))\n",
    "print(len(mdf))\n",
    "print(mdf[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# if not os.path.exists(\"dictionary2\"):\n",
    "#     os.mkdir(\"dictionary2\")\n",
    "# with open(\"dictionary2/person.txt\",\"w\") as fw:\n",
    "#     for name in highPName:\n",
    "#         fw.write(name+\"\\n\")\n",
    "# with open(\"dictionary2/location.txt\",\"w\") as fw:\n",
    "#     for name in highLName:\n",
    "#         fw.write(name+\"\\n\")\n",
    "with open(\"dictionary/webpages/organization.txt\",\"w\") as fw:\n",
    "    for name in highOName:\n",
    "        fw.write(name+\"\\n\")\n",
    "with open(\"dictionary/webpages/misc.txt\",\"w\") as fw:\n",
    "    for name in highMName:\n",
    "        fw.write(name+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationSet = set()\n",
    "personSet = set()\n",
    "orgSet = set()\n",
    "with open(\"dictionary4/person.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            personSet.add(line)\n",
    "with open(\"dictionary4/location.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            locationSet.add(line)\n",
    "with open(\"dictionary4/organization.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            orgSet.add(line)\n",
    "            \n",
    "with open(\"dictionary/location.process\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            locationSet.add(line)\n",
    "with open(\"dictionary/person.process\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            personSet.add(line)\n",
    "with open(\"dictionary/org.process\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            orgSet.add(line)\n",
    "            \n",
    "with open(\"dictionary4/person.txt\",\"w\") as fw:\n",
    "    for i in personSet:\n",
    "        fw.write(i+\"\\n\")\n",
    "with open(\"dictionary4/location.txt\",\"w\") as fw:\n",
    "    for i in locationSet:\n",
    "        fw.write(i+\"\\n\")\n",
    "with open(\"dictionary4/organization.txt\",\"w\") as fw:\n",
    "    for i in orgSet:\n",
    "        fw.write(i+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "orgDic = defaultdict(int)\n",
    "miscDic = defaultdict(int)\n",
    "personDic = defaultdict(int)\n",
    "locDic = defaultdict(int)\n",
    "\n",
    "with open(\"dictionary/webpages/organization.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        orgDic[line]+=1\n",
    "with open(\"dictionary/webpages/misc.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        miscDic[line]+=1\n",
    "        \n",
    "with open(\"dictionary/webpages/person.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        personDic[line]+=1\n",
    "        \n",
    "with open(\"dictionary/webpages/location.txt\",\"r\") as fw:\n",
    "    for line in fw:\n",
    "        line = line.strip()\n",
    "        locDic[line]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005\n",
      "2004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "set1 = set(orgDic.keys())\n",
    "set2 = set(miscDic.keys())\n",
    "set3 = set(personDic.keys())\n",
    "set4 = set(locDic.keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in highPName:\n",
    "    set3.add(i)\n",
    "for i in highLName:\n",
    "    set4.add(i)\n",
    "    \n",
    "print(len(set3))\n",
    "    \n",
    "a = set1-set2-set3-set4\n",
    "b = set2-set1-set3-set4\n",
    "c = set3-set1-set2-set4\n",
    "d = set4-set1-set2-set3\n",
    "\n",
    "print(len(c))\n",
    "\n",
    "with open(\"dictionary/webpages/person.txt\",\"w\") as fw:\n",
    "    for i in c:\n",
    "        fw.write(i+\"\\n\")\n",
    "with open(\"dictionary/webpages/location.txt\",\"w\") as fw:\n",
    "    for i in d:\n",
    "        fw.write(i+\"\\n\")\n",
    "with open(\"dictionary/webpages/organization.txt\",\"w\") as fw:\n",
    "    for i in a:\n",
    "        fw.write(i+\"\\n\")\n",
    "with open(\"dictionary/webpages/misc.txt\",\"w\") as fw:\n",
    "    for i in b:\n",
    "        fw.write(i+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
